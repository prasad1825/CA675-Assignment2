## PRE-PROCESSING DATASET on GOOGLE CLOUD PLATFORM (GCP)

### an original dataset is collected  at https://www.kaggle.com/ananaymital/us-used-cars-dataset 
### The dataset is downloaded and uploaded to the bucket name bucket_dao_nguyen7_2 in project namely CA675 A2 2020

# A Hadoop cluster namely cluster-8344-m on project CA675 A2 2020 has been used as a working environment to implement data cleaning and querying with Pig and Hive. 
 



---HADOOP-----------
#The CSV file was copied to the cluster from the bucket.
hadoop fs -mkdir /pig
hadoop fs -cp 'gs://bucket_dao_nguyen7_2/used_cars_data.csv' /pig

---PIG-----------
#It is the fact that the entry data contains a field with commas and line-break characters. Consequently, the functions such as CSVLoader and PigStorage did not work properly to handle that issue. Instead, CSVExcelStorage has been selected due to its support for loading multi line data. This function is available in the piggybank library which can be downloaded at https://cwiki.apache.org/confluence/display/PIG/PiggyBank and registered into Hadoop as follows:

register piggybank.jar

#Load data from the five CSV files into Pig

loadData = Load 'hdfs://cluster-8344-m/pig/used_cars_data.csv' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',','YES_MULTILINE') AS (vin: chararray, back_legroom: chararray, bed:chararray, bed_height:chararray, bed_length:chararray, body_type:chararray,cabin:chararray, city:chararray, city_fuel_economy:int, combine_fuel_economy:int,daysonmarket: int, dealer_zip:chararray, description:chararray, engine_cylinders:chararray, engine_displacement:chararray, engine_type:chararray, exterior_color:chararray, fleet:chararray, frame_damaged:chararray, franchise_dealer:chararray, franchise_make:chararray, front_legroom:chararray, fuel_tank_volume:chararray, fuel_type:chararray, has_accidents: boolean, height:chararray,       highway_fuel_economy:chararray, horsepower:chararray, interior_color:chararray, isCab: boolean, is_certified: boolean, is_cpo: boolean, is_new: boolean, is_oemcpo:chararray, latitude:double, length:chararray,  listed_date: datetime, listing_color:chararray, listing_id:chararray, longitude: double,        main_picture_url:chararray, major_options:chararray, make_name:chararray, maximum_seating:chararray,  mileage:double, model_name:chararray, owner_count:chararray, power:chararray, price: double, salvage:chararray,  savings_amount:double, seller_rating:chararray, sp_id:chararray, sp_name:chararray, theft_title:chararray,        torque:chararray, transmission:chararray, transmission_display:chararray, trimId:chararray, trim_name:chararray,  vehicle_damage_category:chararray, wheel_system:chararray, wheel_system_display:chararray,  wheelbase:chararray, width:chararray, year:int);

#Generated data into a table with only necessary fields. Specially, the field Description has been cleaned using REPLACE functions. In particular, commas has been eliminated and replaced by semi-colon characters. It is an essential process so that the data can be properly loaded into Hive tables in the later task.

generateData =FOREACH loadData GENERATE vin, model_name, franchise_make, make_name, is_new,  listed_date, daysonmarket,year, price, savings_amount, engine_type,body_type,city, city_fuel_economy, highway_fuel_economy,  fuel_type, fuel_tank_volume, interior_color, listing_color,  maximum_seating, mileage, transmission, transmission_display, wheel_system_display,  latitude, longitude, REPLACE (description,',',';') as description ;

# Filtered data rows to eliminate rows with at least one null field

filterData_notnull = FILTER generateData  by NOT ((vin IS NULL) OR (model_name IS NULL) OR (franchise_make IS NULL) OR (make_name IS NULL) OR (is_new IS NULL) OR (listed_date IS NULL) OR (daysonmarket IS NULL) OR (year IS NULL) OR (price IS NULL) OR (savings_amount IS NULL) OR (engine_type IS NULL) OR (body_type IS NULL) OR (city IS NULL) OR (city_fuel_economy IS NULL) OR (highway_fuel_economy IS NULL) OR (fuel_type IS NULL) OR (fuel_tank_volume IS NULL) OR (interior_color IS NULL) OR (listing_color IS NULL)  OR (maximum_seating IS NULL) OR (mileage IS NULL) OR (transmission IS NULL) OR (transmission_display IS NULL) OR (wheel_system_display IS NULL) OR (latitude IS NULL) OR (longitude IS NULL) OR (description IS NULL));

# Filtered data rows to eliminate rows with at least one blank field

filterData_notnull_notblank = FILTER filterData_notnull  by NOT ((vin =='') OR (model_name =='') OR (franchise_make =='') OR (make_name =='')   OR (engine_type =='') OR  (body_type =='') OR (city =='') OR (fuel_type =='') OR (fuel_tank_volume =='') OR (interior_color =='') OR (listing_color =='')  OR (maximum_seating =='') OR (transmission =='') OR (transmission_display =='') OR (wheel_system_display =='') OR (description ==''));

# Filtered data rows to eliminate rows with at least one 'N/A' field

filterData_notnull_notblank_na = FILTER filterData_notnull_notblank  by NOT ((vin =='N/A') OR (model_name =='N/A') OR (franchise_make =='N/A') OR (make_name =='N/A')   OR (engine_type =='N/A') OR  (body_type =='N/A') OR (city =='N/A') OR (fuel_type =='N/A') OR (fuel_tank_volume =='N/A') OR (interior_color =='N/A') OR (listing_color =='N/A')  OR (maximum_seating =='N/A') OR (transmission =='N/A') OR (transmission_display =='N/A') OR (wheel_system_display =='N/A') OR (description =='N/A'));


---HADOOP-----
#Stored The filtered data into HDFS /FinalHive

STORE filterData_notnull_notblank_na INTO '/FinalHive' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',','YES_MULTILINE');

#After the storage, Pig has divided the result in _SUCCESS file and part-m- files in /FinalHive in HDFS. The log file namely SUCCESS will block the load function of Hive so this file need to be deleted with the following command:

hadoop fs -rm /FinalHive/_SUCCESS

# part-m- files in /FinalHive were merged into only file 

hadoop fs -getmerge /FinalHive/ /home/dao_nguyen7/hive_used_cars_data.csv

---hadoop fs -put hive_used_cars_data.csv 'gs://bucket_dao_nguyen7_3'
---> Put csv file to 'gs://bucket_dao_nguyen7_3' with pulic link  https://storage.googleapis.com/bucket_dao_nguyen7_3/hive_used_cars_data.csv, which support for connecting to visualisation tool.

---HIVE----


CREATE external TABLE IF not exists hive_UsedCars  (vin string, model_name string, franchise_make string, make_name string, is_new boolean,  listed_date string, daysonmarket int,year int, price double, savings_amount double, engine_type string,body_type string,city string, city_fuel_economy int, highway_fuel_economy int,  fuel_type string, fuel_tank_volume string, interior_color string, listing_color string, maximum_seating string, mileage double,    transmission string, transmission_display string,  wheel_system_display string,  latitude double, longitude double, description string)  ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';

Load data local inpath 'hive_used_cars_data.csv' overwrite into table hive_UsedCars;

